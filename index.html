<!DOCTYPE html>

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-178038666-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "UA-178038666-1");
  </script>

  <title>Kumar Ayush - Personal webpage</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link
    href="https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
    rel="stylesheet" />
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous" />
  <script src="./css/jquery-3.5.1.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js"
    integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
    crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css" />
  <script src="https://kit.fontawesome.com/b939870cfb.js" crossorigin="anonymous"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="shortcut icon" href="./images/favicon.ico" />
  <script src="./css/main.js"></script>
  <link rel="stylesheet" href="./css/main.css" />
  <base target="_blank">
</head>

<body>
  <nav class="navbar fixed-top navbar-expand-md">
    <div class="container">
      <a class="navbar-brand" target="_self" href="#"> Kumar Ayush </a>
      <button class="navbar-toggler navbar-light" type="button" data-toggle="collapse" data-target="#main-navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="main-navigation">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link" target="_self" href="#pubs">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" target="_self" href="#patents">Patents</a>
          </li>
          <!-- <li class="nav-item">
            <a class="nav-link" target="_self" href="#code">Code</a>
          </li> -->
          <!-- <li class="nav-item">
            <a class="nav-link" href="#teaching">Teaching</a>
          </li> -->
          <li class="nav-item">
            <a class="nav-link" href="./files/kayush_cv.pdf" target="_blank">CV</a>
          </li>
          <!-- <li class="nav-item">
            <a class="nav-link" href="https://kmrayush.github.io/blog">Blog</a>
          </li> -->
        </ul>
      </div>
    </div>
  </nav>

  <div class="full-project-divider top-divider"></div>

  <!-- Biography: first section of webpage -->
  <div class="container" id="aboutme">
    <div class="bio">
      <div class="box profile">
        <div class="headshot">
          <img src="./images/headshot.jpg" alt="Kumar Ayush" />
        </div>
        <h2 class="name section-heading"></h2>
        <!-- <h3 class="affil">Research Scientist, Sony AI</h3> -->
        <h3 class="email">kayush@cs.stanford.edu</h3>
        <h3 class="email">kmrayush@google.com</h3>
      </div>
      <div class="box about-me">
        <p>
          I am a lead research engineer at <a href="https://ai.google/">Google AI</a> working on Health AI Foundation Models. I am also a PhD student at <a href="https://www.stanford.edu/">Stanford University</a> studying machine learning and foundation models for healthcare.
        </p>
        <p>
          I recieved my Master's in Computer Science (with <span class="redtext">Distinction in Research</span>) from <a href="https://www.stanford.edu/">Stanford University</a> and Bachelor's in Computer Science and Engineering with Honours from <a href="https://www.iitkgp.ac.in/">IIT Kharagpur</a> where I also received the <span class="redtext">Best Bachelor's Thesis Award</span>. My work has been recognized by <span class="redtext">Forbes 30 under 30</span> in <a href="https://www.forbes.com/profile/kumar-ayush/">Science</a> category. I have also featured in  <span class="redtext">Forbes 30 under 30 India</span> as a Special Mention in the Artificial Intelligence catrogy.
        </p>

        <p>
          Currently, I am building large-scale foundational models and multimodal LLMs for wearable sensor data to provide consumers with personalized health insights.
        </p>  
        <!-- <p>
          I received my PhD from <a href="https://www.princeton.edu/">Princeton University</a> where I was advised by
          Prof. Prateek Mittal and Prof. Mung Chiang. I previously interned at <a href="https://ai.facebook.com/" target="_blank">Meta AI</a>  (AI Red Team) and
          <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-redmond/" target="_blank">Microsoft
            Research</a>. I
          have been fortunate to receive
          <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/winners"
            target="_blank">Qualcomm Innovation Fellowship</a> and the <a href="https://sites.google.com/view/advml/advml-rising-star-award">Rising Star Award</a> in adversarial machine learning. I previously organized the first
            <a href="https://vsehwag.github.io/SPML_seminar/" target="_blank">seminar series on Security & Privacy in
              Machine Learning (SPML)</a> at Princeton University.
        </p> -->
        <ul>
          <li>
            <a href="https://scholar.google.com/citations?user=gIlnMF8AAAAJ&hl=en" target="_blank"><i
                class="ai ai-google-scholar"></i></a>
          </li>
          <!-- <li>
            <a href="https://dblp.org/pid/187/5613.html" target="_blank"><i class="ai ai-dblp"></i></a>
          </li> -->
          <li>
            <a href="https://www.linkedin.com/in/kmrysh/" target="_blank"><i class="fab fa-linkedin"></i></a>
          </li>
          <li>
            <a href="https://x.com/kmr_ayush" target="_blank"><i class="fab fa-twitter"></i></a>
          </li>
          <!-- <li>
            <a href="https://github.com/VSehwag" target="_blank"><i class="fab fa-github"></i></a>
          </li> -->
        </ul>
      </div>
      <!-- <div class="interests">
        <div>
          <strong>Research interests.</strong> Uncovering and mitigating safety risks in the development of next-generation of trustworthy AI systems.
          <ul>
            <li>
              <strong>Safer generative AI.</strong> We have demonstrated privacy risks in real-world diffusion models and developed privacy-preserving sampling and training methods [<a href="https://www.usenix.org/system/files/usenixsecurity23-carlini.pdf">1</a>, <a href="https://openreview.net/forum?id=vuVGcl0ed1">2</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/7058bc192a37f5e5a57398887b05f6f6-Abstract-Conference.html">3</a>, <a href="https://arxiv.org/abs/2212.04486">4</a>]. We have also developed techniques and benchmarked automated generation of adversarial and unsafe content from generative models [<a href="https://arxiv.org/abs/2203.17260">5</a>, <a href="./projects/2024/jbb/pl.html">6</a>].
            </li>
            <li>
              <strong>Responsible data synthesis.</strong> Concerned by the vast amount of generative content online, we've recently developed techniques to identify synthetic samples [<a href="./projects/2024/watermarks/pl.html">7</a>], even in the absence of artificial watermarks, and tracing them to source generative models [<a href="./projects/2024/tracing/pl.html">8</a>].
            </li>
            <li>
              <strong>Robust machine learning.</strong> We have conducted an in-depth exploration of adversarial robust learning, including circumventing its higher sample complexity using synthetic data [<a href="https://openreview.net/forum?id=WVX0NNVBBkV">9</a>], finding fundamental limits on robustness [<a href="https://proceedings.mlr.press/v139/bhagoji21a">10</a>], demonstrating higher robustness with transformers [<a href="https://openreview.net/forum?id=IztT98ky0cKs">11</a>], robustness across threat models [<a href="https://www.usenix.org/conference/usenixsecurity21/presentation/xiang">12</a>, <a href="https://proceedings.mlr.press/v202/wu23h/wu23h.pdf">13</a>, <a href="https://openreview.net/forum?id=SbAaNa97bzp">14</a>], the effect of model scaling and compression [<a href="https://arxiv.org/abs/2312.13131">15</a>, <a href="https://proceedings.neurips.cc/paper/2020/hash/e3a72c791a69f87b05ea7742e04430ed-Abstract.html">16</a>], and adversarial risks in transitioning from closed-domain to open-world systems [<a href="https://dl.acm.org/doi/10.1145/3338501.3357372">17</a>, <a href="https://openreview.net/pdf?id=v5gjXpmR8J">18</a>].
            </li>
            <li>
              <strong>Benchmarking progress in AI safety.</strong> We developed the widely adopted RobustBench benchmark [<a href="https://robustbench.github.io/">19</a>], followed by MultiRobustBench to account for multiple attacks [<a href="https://proceedings.mlr.press/v202/dai23c">20</a>], and most recently JailbreakBench [<a href="./projects/2024/jbb/pl.html">6</a>] to benchmark progress on jailbreaks against LLMs. We have also written a detailed discussion on nuanced similarity and distinction in security and safety approaches towards Trustworthy AI [<a href="./projects/2024/sec_vs_safety/pl.html">21</a>].
            </li>
          </ul>
        </div>
      </div> -->
    </div>
  </div>
  <!-- News: Second section of the webpage-->
  <!-- <div class="news container">
    <div class="news-mini-container">
      <div class="news-grid">
        <p class="section-heading">News</p>
        <div class="flex-container">
          <div>02/2023</div>
          <div class="news-text">
            New paper on extracting training data from diffusion models (<a
              href="https://arxiv.org/abs/2301.13188">pdf</a>)
          </div>
        </div>
        <div class="flex-container">
          <div>12/2022</div>
          <div class="news-text">
            Presented <a href="https://arxiv.org/abs/2206.09868">our paper</a> on understanding robust representations
            at Neurips'22.
          </div>
        </div>
        <div class="flex-container">
          <div>09/2022</div>
          <div class="news-text">
            Awarded graduate student award for excellence in service (ECE, Princeton University).
          </div>
        </div>
        <div class="flex-container">
          <div>04/2022</div>
          <div class="news-text">
            Awarded <a
              href="https://ece.princeton.edu/news/honorific-fellowships-fund-research-quantum-sensors-and-trustworthy-ai"
              target="_blank">Charlotte Elizabeth Proctor Honorific Fellowship</a>, one of the highest honors at
            Princeton University.
          </div>
        </div>
        <div class="flex-container">
          <div>03/2022</div>
          <div class="news-text">
            Paper on low-density sampling from diffusion models got accepted at
            <a href="https://arxiv.org/abs/2203.17260" target="_blank">CVPR'22</a>.
          </div>
        </div>
        <div class="flex-container">
          <div>01/2022</div>
          <div class="news-text">
            Paper on using synthetic data in robust learning got accepted at
            <a href="https://arxiv.org/abs/2104.09425" target="_blank">ICLR'22</a>.
          </div>
        </div>
        <div class="flex-container">
          <div>08/2021</div>
          <div class="news-text">
            Finished an amazing research internship at
            <a href="https://ai.facebook.com/">Facebook AI</a>.
          </div>
        </div>
        <div class="flex-container">
          <div>05/2021</div>
          <div class="news-text">
            Paper on lower bounds on adversarial robustness accepted at
            <a href="https://icml.cc/">ICML 2021 </a> (<a href="https://arxiv.org/pdf/2104.08382.pdf">pdf</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>04/2021</div>
          <div class="news-text">
            Paper on improving robustness using proxy distributions is now out
            (<a href="https://arxiv.org/abs/2104.09425">pdf</a>)!
          </div>
        </div>

        <div class="flex-container">
          <div>03/2021</div>
          <div class="news-text">
            <a href="https://robustbench.github.io/">RobustBench</a> won best
            paper honorable mention prize at
            <a href="https://aisecure-workshop.github.io/aml-iclr2021/cfp">ICLR AiSecure</a>
            workshop.
          </div>
        </div>
        <div class="flex-container">
          <div>01/2021</div>
          <div class="news-text">
            Self-supervised outlier detection (SSD) paper accepted at
            <a href="https://iclr.cc/Conferences/2021/Dates" target="_blank">ICLR 2021</a>
            (<a href="https://openreview.net/pdf?id=v5gjXpmR8J" target="_blank">pdf</a>,
            <a
              href="https://slideslive.com/38954089/ssd-a-unified-framework-for-selfsupervised-outlier-detection?ref=search">slides</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>01/2021</div>
          <div class="news-text">
            Paper on PatchGuard accepted at
            <a href="https://www.usenix.org/conference/usenixsecurity21">USENIX Security</a>
            2021 (<a href="https://www.usenix.org/system/files/sec21fall-xiang.pdf">pdf</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>10/2020</div>
          <div class="news-text">
            Releasing
            <a href="https://robustbench.github.io" target="_blank">RobustBench</a>, a standardized benchmark for
            adversarial robustness.
          </div>
        </div>
        <div class="flex-container">
          <div>10/2020</div>
          <div class="news-text">
            Work on fast-convergent federated learning to appear in
            <a href="https://www.comsoc.org/publications/journals/ieee-jsac">IEEE JSAC</a>
            (<a href="https://arxiv.org/abs/2007.13137">arxiv</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>09/2020</div>
          <div class="news-text">
            Paper on prning robust networks (Hydra) accepted at
            <a href="https://neurips.cc/">NeurIPS 2020</a>. (<a href="https://vsehwag.github.io/hydra/">webpage</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>07/2020</div>
          <div class="news-text">
            Paper on background check of deep learning - ICML OOL workshop (<a
              href="https://arxiv.org/pdf/2006.14077.pdf">pdf</a>,
            <a href="https://oolworkshop.github.io/program/ool_26.html">video</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>07/2020</div>
          <div class="news-text">
            Work on separability of self-supervised representations, and another
            one on critical evaluation of open-world meachine learning, accepted
            at ICML UDL workshop.
          </div>
        </div>
        <div class="flex-container">
          <div>06/2020</div>
          <div class="news-text">
            Volunteered as junior mentor at
            <a href="https://researchcomputing.princeton.edu/events/princeton-olcf-nvidia-gpu-hackathon">Princeton-OLCF-NVIDIA
              GPU Hackathon.</a>
          </div>
        </div>
        <div class="flex-container">
          <div>05/2020</div>
          <div class="news-text">
            Releasing PatchGuard, a provable defense against adversarial patches
            (<a href="https://arxiv.org/pdf/2005.10884.pdf">Pdf</a>,
            <a href="https://github.com/inspire-group/PatchGuard">Code</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>04/2020</div>
          <div class="news-text">
            Work on pruning robust networks accepted at
            <a href="https://trustworthyiclr20.github.io/" target="_blank">ICLR TTML workshop</a>
            (<a
              href="https://docs.google.com/presentation/d/1yLSnvUR5MFhv-Dp2yuQEF1QuFNffTSomUGuiZsZJmbY/edit?usp=sharing">slides</a>,
            <a
              href="https://slideslive.com/38926541/on-pruning-adversarially-robust-neural-networks?ref=account-folder-46630-folders">video</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>01/2020</div>
          <div class="news-text">
            Taught a mini-course on adversarial attacks & defenses in
            Winterssion 2020 (<a
              href="https://docs.google.com/presentation/d/1bs7xMYndjUshWkgLppmpnle_ZWkVTA7QoOfJ79nG-Ko/edit?usp=sharing">Slides</a>,
            <a
              href="https://colab.research.google.com/drive/1Pyn8zgZUlBKz18kSL0vO0ojBE3AnVpl6?usp=sharing">Colab-notebook</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>09/2019</div>
          <div class="news-text">
            Finished amazing summer research internship at Microsoft Research,
            Redmond.
          </div>
        </div>
        <div class="flex-container">
          <div>08/2019</div>
          <div class="news-text">
            Paper on robust open-world machine learning accepted at
            <a href="https://aisec.cc/">AISec 2019</a> (<a
              href="https://docs.google.com/presentation/d/12NQfyzcztr00gjicu0-BzROV178_fSJNTXMraoCspvw/edit?usp=sharing">Slides</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>05/2019</div>
          <div class="news-text">
            Won
            <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/winners">Qualcomm
              Innovation Fellowship 2019</a>.
          </div>
        </div>
      </div>
    </div>
  </div> -->


  <div class="center-text">
    <strong>I am looking for student researchers/research interns with experience in large scale multimodal foundation models and their applications to healthcare, please reach out if you are interested.</strong>
  </div>
  
  <!-- Publications: The major section in the middle of website-->
  <br>
  <div class="publications container" id="pubs">
    <!-- <div class="publications container" id="pubs"> -->
      <div class="full-project-divider2"><hr /></div>
    <p class="section-heading">Selected Publications</p>
    <!-- Create a copy of pubs-box for a new entry and pubs-section for a group of entries-->
    <!-- <h5>2024</h5> -->

    <div class="pubs-box key-pubs">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/model_arch.png"/>
      </div>
      <div class="pubs-data">
        <p class="title">
          SensorLM: Learning the Language of Wearable Sensors
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Yuwei Zhang*, Siyuan Qiao, A. Ali Heydari, Girish Narayanswamy, Maxwell A Xu, Ahmed Metwally, Jinhua Xu, Jake Garrison, Xuhai Xu, Tim Althoff, Yun Liu, Pushmeet Kohli, Mark Malhotra, Shwetak Patel, Celilia Mascolo, Xin Liu, Daniel McDuff, Yuzhe Yang
        </p>
        <p>
          <span class="venue">Under Review - </span>
          <span class="links">
            <a href="https://www.arxiv.org/pdf/2506.09108" target="_blank">pdf</a>
            <!-- <a href="https://research.google/blog/scaling-wearable-foundation-models/" target="_blank">Google AI blog</a> -->
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/lsm2.png"/>
      </div>
      <div class="pubs-data">
        <p class="title">
          LSM-2: Learning from Incomplete Wearable Sensor Data
        </p>
        <p class="authors">
          Maxwell A Xu*, Girish Narayanswamy*, <em>Kumar Ayush</em>, Dimitris Spathis, Shun Liao, Shyam A. Tailor, Ahmed Metwally, A. Ali Heydari, Yuwei Zhang, Jake Garrison, Samy Abdel-Ghaffar, Xuhai Xu, Ken Gu, Jacob Sunshine, Ming-Zher Poh, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Yuzhe Yang, Mark Malhotra, Shwetak Patel, James Matthew Rehg, Xin Liu, Daniel McDuff
        </p>
        <p>
          <span class="venue">Under Review - </span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2506.05321" target="_blank">pdf</a>  
            <!-- <a href="https://research.google/blog/scaling-wearable-foundation-models/" target="_blank">Google AI blog</a> -->
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>
  

    <div class="pubs-box key-pubs">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/bridge.png"/>
      </div>
      <div class="pubs-data">
        <p class="title">
          Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning
        </p>
        <p class="authors">
          Jaedong Hwang*, Kumar Tanmay*, Seok-Jin Lee, Ayush Agrawal, Hamid Palangi, <em>Kumar Ayush</em>, Ila R Fiete, Paul Pu Liang
        </p>
        <p>
          <span class="venue">Under Review</span>
          <span class="links">
            <!-- <a href="https://arxiv.org/pdf/2506.05321" target="_blank">pdf</a>   -->
            <!-- <a href="https://research.google/blog/scaling-wearable-foundation-models/" target="_blank">Google AI blog</a> -->
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>

  
  
    <div class="pubs-box">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/radar.png"/>
      </div>
      <div class="pubs-data">
        <p class="title">
          RADAR: Benchmarking Language Models on Imperfect Tabular Data
        </p>
        <p class="authors">
          Ken Gu, Zhihan Zhang, Kate Lin, Yuwei Zhang, Akshay Paruchuri, Hong Yu, Mehran Kazemi, <em>Kumar Ayush</em>, A. Ali Heydari, Maxwell A Xu, Yun Liu, Ming-Zher Poh, Yuzhe Yang, Mark Malhotra, Shwetak Patel, Hamid Palangi, Xuhai Xu, Daniel McDuff, Tim Althoff, Xin Liu
        </p>
        <p>
          <span class="venue">Under Review - </span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2506.08249" target="_blank">pdf</a> |
            <a href="https://github.com/kenqgu/RADAR" target="_blank">Code</a> |
            <a href="https://huggingface.co/datasets/kenqgu/RADAR" target="_blank">Dataset</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/factuality.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Language Models’ Factuality Depends on the Language of Inquiry
        </p>
        <p class="authors">
          Tushar Aggarwal*, Kumar Tanmay*, Ayush Agrawal*, <em>Kumar Ayush</em>, Hamid Palangi, Paul Pu Liang
        </p>
        <p>
          <span class="venue">Submitted to EMNLP 2025 -</span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2502.17955" target="_blank">pdf</a>
            <!-- <a href="https://research.google/blog/advancing-personal-health-and-wellness-insights-with-ai/" target="_blank">Google AI blog</a> -->
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/coach.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Substance over style: Evaluating Proactive Conversational Coaching Agents
        </p>
        <p class="authors">
          Vidya Srinivas, Xuhai Xu, Xin Liu, <em>Kumar Ayush</em>, Isaac Galatzer-Levy, Shwetak Patel, Daniel McDuff, Tim Althoff
        </p>
        <p>
          <span class="venue">ACL 2025 -</span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2503.19328" target="_blank">pdf</a>
            <!-- <a href="https://research.google/blog/advancing-personal-health-and-wellness-insights-with-ai/" target="_blank">Google AI blog</a> -->
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>



    <div class="pubs-box key-pubs">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/lsm.jpg" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Scaling Wearable Foundation Models
        </p>
        <p class="authors">
          Girish Narayanswamy*, Xin Liu*, <em>Kumar Ayush</em>, Yuzhe Yang, Xuhai Xu, Shun Liao, Jake Garrison, Shyam Tailor, Jake Sunshine, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Jiening Zhan, Mark Malhotra, Shwetak Patel, Samy Abdel-Ghaffar, Daniel McDuff
        </p>
        <p>
          <span class="venue">ICLR 2025 - </span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2410.13638" target="_blank">pdf</a> | 
            <a href="https://research.google/blog/scaling-wearable-foundation-models/" target="_blank">Google AI blog</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>



    <div class="pubs-box key-pubs">
      <div class="pubs-image" margin-right: 1em>
        <img src="./projects/phia.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Transforming Wearable Data into Health Insights using Large Language Model Agents
        </p>
        <p class="authors">
          Mike A. Merrill, Akshay Paruchuri, Naghmeh Rezaei, Geza Kovacs, Javier Perez, Yun Liu, Erik Schenck, Nova Hammerquist, Jake Sunshine, Shyam Tailor, <em>Kumar Ayush</em>, Hao-Wei Su, Qian He, Cory McLean, Mark Malhotra, Shwetak Patel, Jiening Zhan, Tim Althoff, Daniel McDuff, Xin Liu
        </p>
        <p>
          <span class="venue">Preprint - </span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2406.06464" target="_blank">pdf</a> | 
            <a href="https://research.google/blog/advancing-personal-health-and-wellness-insights-with-ai/" target="_blank">Google AI blog</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using signature from the latent autoencoders, we propose an approach to trace synthetic images back to the source latent generative model.
        </p> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/drosophila.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Diverse cell-specific patterns of alternative polyadenylation in Drosophila
        </p>
        <p class="authors">
          Seungjae Lee, Yen-Chung Chen, <em>Kumar Ayush (Part of FCA Consortium)</em>, Austin E. Gillen, J. Matthew Taliaferro, Bart Deplancke, Hongjie Li, Eric C. Lai.
        </p>
        <p>
          <span class="venue">Nature Communications - </span>
          <span class="links">
            <a href="https://www.nature.com/articles/s41467-022-32305-0" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          We consider the cost of hyperparameter optimization in differentially private learning and propose a strategy that prvoides linear scaling of hyperparameters, thus reducing the privacy cost and simultaneously achieving state-of-the-art performance across 22 benchmark tasks in CV and NLP. 
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/fca.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Fly Cell Atlas: a single-cell transcriptomic atlas of the adult fruit fly
        </p>
        <p class="authors">
          Hongjie Li, ..., <em>Kumar Ayush (Part of FCA Consortium)</em>, ..., Stein Aerts
        </p>
        <p>
          <span class="venue">Science - </span>
          <span class="links">
            <a href="https://www.science.org/doi/10.1126/science.abk2432" target="_blank">pdf</a> | 
            <a href="https://flycellatlas.org/#about" target="_blank">webpage</a>
          </span>
        </p>
        <!-- <p class="summary">
          A centralized benchmark for 1) repository of jailbreaking attacks and artifacts, 2) standardized evaluation framework, and 3) up-to-date leaderboard. 
        </p> -->
      </div>
    </div>
    
    <!-- <h4>2023</h4> -->
    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/efficient.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Efficient Conditional Pre-training for Transfer Learning
        </p>
        <p class="authors">
          Shuvam Chakraborty, <em>Kumar Ayush</em>*, Burak Uzkent*, Kumar Tanmay, Evan Sheehan, Stefano Ermon
        </p>
        <p>
          <span class="venue">CVPR L3D-IVU 2022 - </span>
          <span class="links">
            <a href="https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Chakraborty_Efficient_Conditional_Pre-Training_for_Transfer_Learning_CVPRW_2022_paper.pdf" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          We show that pre-training on data from random processes enables better performance during differentially private finetuning, while simultaneously avoiding privacy leakage associated with real pretraining images. 
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/geoawaressl.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Geography-Aware Self-Supervised Learning
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Burak Uzkent*, Chenlin Meng*, Kumar Tanmay, Marshall Burke, David Lobell, Stefano Ermon
        </p>
        <p>
        <span class="venue">ICCV 2021 - </span>
        <span class="links"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ayush_Geography-Aware_Self-Supervised_Learning_ICCV_2021_paper.pdf" target="_blank">pdf</a> | 
          <a href="https://geography-aware-ssl.github.io/">webpage</a> | 
          <a href="https://github.com/sustainlab-group/geography-aware-ssl" target="_blank">code</a>
        </span>
        </p>
        <!-- <p class="summary">
          This was one of the first works to demonstrate significant memorization of real-world images in web-scale text-to-image generative models (Stable Diffusion, ImageN). Our findings further motivated web-scale data deduplication in training dataset of generative models.
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/nda.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Negative Data Augmentation
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Abhishek Sinha*, Jiaming Song*, Burak Uzkent, Hongxia Jin, Stefano Ermon
        </p>
        <p>
          <span class="venue">ICLR 2021 - </span>
          <span class="links">
            <a href="https://openreview.net/pdf?id=Ovp8dvB8IBH" target="_blank">pdf</a> | 
            <a href="https://www.youtube.com/watch?v=K-1mN2mz66k" target="_blank">video</a>
          </span>
        </p>
        <!-- <p class="summary">
          We show that test-time adaptation, a technique that aims to improve performance at test time, also increases exposure to novel security risks.
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/rlpoverty.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Efficient Poverty Mapping from High Resolution Remote Sensing Images
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Burak Uzkent*, Kumar Tanmay, Marshall Burke, David Lobell, Stefano Ermon
        </p>
        <p>
          <span class="venue">AAAI 2020 (<span class="redtext">Oral</span>) -</span>
          <span class="links">
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/16072" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          Going beyond single-attack robustness (RobustBench), we develop a standardized benchmark for multi-attack threat vectors.
        </p> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/povestimation.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Generating Interpretable Poverty Maps using Object Detection in Satellite Images
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Burak Uzkent*, Marshall Burke, David Lobell, Stefano Ermon
        </p>
        <p>
          <span class="venue">IJCAI 2020 - </span>
          <span class="links">
            <a href="https://arxiv.org/abs/2002.01612" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          Contrary to the conventional wisdom of using heavy data augmentation in ViTs, we showed that a lighter data
          augmentation (along with other bag-of-tricks) achieves state-of-the-art performance with ViTs adversarial training.
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/sievenet.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Surgan Jandial*, Ayush Chopra*, Mayur Hemani, Abhijeet Halwai, Balaji K
        </p>
        <p>
          <span class="venue">WACV 2020 (also at AI for Content Creation Workshop, CVPR 2020) - </span>
          <span class="links">
            <a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Jandial_SieveNet_A_Unified_Framework_for_Robust_Image-Based_Virtual_Try-On_WACV_2020_paper.pdf" target="_blank">pdf</a> | 
            <a href="https://venturebeat.com/2020/01/22/adobes-ai-lets-you-preview-any-item-of-clothing-on-a-virtual-body-model/?fbclid=IwAR1pEa6-XiSuCUp2rFxP-ekuqKLMrqXXwZyPetbvmPq0Y6ZZF03TV1eilik" target="_blank">Venture Beat</a> | 
            <a href="https://beebom.com/adobes-ai-fits-clothes-any-body-type/" target="_blank">Beebom</a> | 
            <a href="https://blog.adobe.com/en/publish/2020/05/26/adobe-sneaks-changing-outfits-in-ecommerce-with-ai" target="_blank">Adobe Blog</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>

    <!-- <h4>2022</h4> -->
    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/compatibility.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Towards a Unified Framework for Fashion Compatibility and Outfit Recommendation
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Anirudh Singhal*, Utkarsh Patel*, Ayush Chopra*, Balaji K
        </p>
        <p>
          <span class="venue">WACV 2020 - </span>
          <span class="links">
            <a href="http://openaccess.thecvf.com/content_WACV_2020/papers/Singhal_Towards_a_Unified_Framework_for_Visual_Compatibility_Prediction_WACV_2020_paper.pdf" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          Our work showed strong generalization of diffusion models in the tail of the data distribution and developed adaptive sampling techniques to generate high-fidelity samples from the tail of the data distribution.
        </p> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/tryonseg.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Powering Virtual Try-On via Auxiliary Human Segmentation Learning
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Surgan Jandial*, Ayush Chopra*, Balaji K
        </p>
        <p>
          <span class="venue">Second Workshop on Computer Vision for Fashion, Art and Design @ ICCV 2019 - </span>
          <span class="links">
            <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Ayush_Powering_Virtual_Try-On_via_Auxiliary_Human_Segmentation_Learning_ICCVW_2019_paper.pdf" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/patch.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Robust Cloth Warping via Multi-Scale Patch Adversarial Loss for Virtual Try-On Framework
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Surgan Jandial*, Ayush Chopra*, Mayur Hemani, Balaji K
        </p>
        <p>
          <span class="venue">10th International Workshop on Human Behaviour Understanding (HBU) @ ICCV 2019 - </span>
          <span class="links">
            <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Ayush_Robust_Cloth_Warping_via_Multi-Scale_Patch_Adversarial_Loss_for_Virtual_ICCVW_2019_paper.pdf" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/guidedsvm.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Improving Classification Performance of Support Vector Machines via Guided Custom Kernel Search
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Abhishek Sinha*
        </p>
        <p>
          <span class="venue">The Genetic and Evolutionary Computation Conference (ACM GECCO) 2019 - </span>
          <span class="links">
            <a href="https://dl.acm.org/citation.cfm?id=3321923" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>
  

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/retrieval.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Powering Robust Fashion Retrieval with Information Rich Feature Embeddings
        </p>
        <p class="authors">
          Ayush Chopra, Abhishek Sinha, Hiresh Gupta, Mausoom Sarkar, <em>Kumar Ayush</em>, Balaji K
        </p>
        <p>
          <span class="venue">Understanding Subjective Attributes of Data: Focus on Fashion and Subjective Search Workshop @ CVPR 2019 - </span>
          <span class="links">
            <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/FFSS-USAD/Chopra_Powering_Robust_Fashion_Retrieval_With_Information_Rich_Feature_Embeddings_CVPRW_2019_paper.pdf" target="_blank">pdf</a>
          </span>
        </p>
        <p style="color:red;">Best Paper Award</p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/hbdca.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Supporting Throughput Fairness in IEEE 802.11ac Dynamic Bandwidth Channel Access: A Hybrid Approach
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Raja Karamakar, Varun Rawal, Pradyumna K. Bishoyi, Samiran Chattopadhyay, Sandip Chakraborty
        </p>
        <p>
          <span class="venue">IEEE Conference on Local Computer Networks (LCN) 2017 - </span>
          <span class="links">
            <a href="http://ieeexplore.ieee.org/document/8109388/" target="_blank">pdf</a> |
            <a href="https://kayush95.github.io/pdfs/HADBCA_Slides.pdf" target="_blank">slides</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>


    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./projects/ar.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Enhanced Personalized Targeting using Augmented Reality
        </p>
        <p class="authors">
          Gaurush Hiranandani, <em>Kumar Ayush</em>, Atanu R Sinha, Sai Varun Reddy Maram, Chinnaobireddy Varsha, Pranav Maneriker
        </p>
        <p>
          <span class="venue">IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2017 - </span>
          <span class="links">
            <a href="http://ieeexplore.ieee.org/abstract/document/8088451/" target="_blank">pdf</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/retina.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Microscopy Images: Automated Vessel Segmentation in Retinal Fundus Image as Test Case
        </p>
        <p class="authors">
          Avisek Lahiri, <em>Kumar Ayush</em>, Prabir Kumar Biswas, Pabitra Mitra
        </p>
        <p>
          <span class="venue">Computer Vision for Microscopy Image Analysis (CVMI) Workshop @ CVPR 2017 - </span>
          <span class="links">
            <a href="http://openaccess.thecvf.com/content_cvpr_2017_workshops/w8/papers/Lahiri_Generative_Adversarial_Learning_CVPR_2017_paper.pdf" target="_blank">pdf</a> |
            <a href="https://kayush95.github.io/pdfs/VesselSegmentation_Slides.pdf" target="_blank">slides</a> | 
            <a href="https://github.com/kayush95/Automated-Vessel-Segmentation" target="_blank">code</a>
          </span>
        </p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>   

    <div class="pubs-box key-pubs">
      <div class="pubs-image">
        <img src="./projects/deepfix.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          DeepFix: A Fully Convolutional Neural Network for predicting Human Eye Fixations
        </p>
        <p class="authors">
          Srinivas S. S. Kruthiventi, <em>Kumar Ayush</em>, R. Venkatesh Babu.
        </p>
        <p>
          <span class="venue">IEEE Transactions on Image Processing 2017 - </span>
          <span class="links">
            <a href="http://ieeexplore.ieee.org/document/7937829/" target="_blank">pdf</a> |
            <a href="https://kayush95.github.io/pdfs/DeepFix_Slides.pdf" target="_blank">slides</a>
          </span>
        </p>
        <p style="color:red;">Winner of Saliency Prediction - Large Scale Scene Understanding Challenge @ CVPR 2016</p>
        <!-- <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p> -->
      </div>
    </div>   
    

    <!-- <div class="full-project-divider2">
      <hr />
    </div> -->

    <!-- <div class="container" id="code">
      <p class="section-heading-small">Selected Open Source Repositories</p>
      <div class="pubs-section work-in-progress">
        <ul class="simple-ord-list">
          <li><a href="https://github.com/RobustBench/robustbench">https://github.com/RobustBench/robustbench</a> | &#9733; 598 | <em>RobustBench leaderboard</em></li>
          <li><a href="https://github.com/VSehwag/minimal-diffusion">https://github.com/VSehwag/minimal-diffusion</a> | &#9733; 214 | <em>Minimalistic implementation of diffusion models</em></li>
          <li><a href="https://github.com/inspire-group/SSD">https://github.com/inspire-group/SSD</a> | &#9733; 125 | <em>Self-supervised outlier detection</em></li>
          <li><a href="https://github.com/inspire-group/hydra">https://github.com/inspire-group/hydra</a> | &#9733; 88 | <em>Pruning adversarial robust networks</em></li>
          <li><a href="https://github.com/inspire-group/proxy-distributions">https://github.com/inspire-group/proxy-distributions</a> | &#9733; 26 | <em>Improving adversarial robustness using synthetic data</em></li>
          <li><a href="https://github.com/inspire-group/OOD-Attacks">https://github.com/inspire-group/OOD-Attacks</a> | &#9733; 12 | <em>Robust open-world machine learning</em></li>
          <li><a href="https://github.com/inspire-group/robust_representation_similarity">https://github.com/inspire-group/robust_representation_similarity</a> | &#9733; 6 | <em>Representation similarity analysis for robust and non-robust networks</em></li>
        </ul>

      <p class="section-heading-small">Invited Talks</p>
      <div class="pubs-section work-in-progress">
        <ul class="simple-ord-list">
          <li>On safety risks of generative AI - From ChatGPT to DallE.3 | <em>Nov 2023</em> | <em>Columbia University</em></li>
          <li>Prospects and pitfalls of modern generative models - An AI safety perspective  | <em>Feb 2023</em> | <em>AAAI</em></li>
          <li>Enhancing machine learning using synthetic data distilled from generative models | <em>Jan 2023</em> | <em>MSR</em></li>
          <li>Role of synthetic data in trustworthy machine learning | <em>May 2022</em> | <em>UChicago, UBerkeley</em></li>
          <li>A generative approach to robust machine learning | <em>Mar 2022</em> | <em>CISS Conference</em></li>
          <li>A generative approach to robust machine learning | <em>Jan 2022</em> | <em>RIKEN-AIP TrustML Young Scientist Seminar</em></li>
          <li>Generating novel hard-instances form low-density regions using generative models | <em>Aug 2021</em> | <em>Meta AI</em></li>
          <li>A primer on adversarial machine learning | <em>July 2021</em> | <em>Princeton-Intel REU Seminar</em></li>
          <li>Embedding data distribution to make machine learning more reliable | <em>Mar 2021</em> | <em>EPFL</em></li>
          <li>Private Deep Learning Made Practical | <em>Oct 2019</em> | <em>Qualcomm</em></li>
        </ul>

      <p class="section-heading-small">Academic Services</p>
      <strong>Teaching and Mentoring</strong>
      <div class="pubs-section work-in-progress">
        <ul class="simple-ord-list">
          <li>Lecture on basics of adversarial machine learning | <em>Princeton-Intel REU Seminar 2021</em></li>
          <li>Teaching assistant for ECE 574: Security & Privacy | <em>Fall 2021 - Princeton University</em> </li>
          <li>Taught a mini-course on adversarial attacks & defenses | <em>Winterssion 2020 - Princeton University</em></li>
          <li>Teaching assistant for ELE 535: Machine Learning and Pattern Recognition | <em>Fall 2019 - Princeton University</em></li>
          <li>Mentored ten students in AI research over the years: <em>Edoardo Debenedetti, Rajvardhan Oak, Christian Cianfarani, Tinashe Handina, Matteo Russo, Xianghao Kong, Song Wen, Minzhou Pan, Zhenting Wang, Jie Ren.</em> </li>
        </ul>
      <strong>Other Services</strong>
      <div class="pubs-section work-in-progress">
        <ul class="simple-ord-list">
          <li>Workshop organizer - ICCV 2023 ARROW workshop, CVPR 2023 Workshop of Adversarial Machine Learning on Computer Vision: Art of Robustness 2023</li>
          <li>Program committe member for IEEE Conference on Secure and Trustworthy Machine Learning - 2023</li>
          <li>Organized more than 20 talks on security & privacy in machine learning (<a href="https://vsehwag.github.io/SPML_seminar/">SPML seminar series</a>) - 2022</li>
          <li>One of the core maintainers of Adversarial Robustness Benchmark | <a href="https://robustbench.github.io/"
            target="_blank">robustbench.github.io</a></li>
          <li>Volunteered as junior mentor at Princeton-OLCF-NVIDIA GPU Hackathon | <em>June 2020 - Princeton University</em> </li>
          <li>Reviewed more than 50 papers for major computer vision and machine learning conferences and journals.</em></li>
        </ul>
    </div> -->
  </div>


  <br>
  <div class="patents container" id="patents">
    <!-- <div class="publications container" id="pubs"> -->
      <div class="full-project-divider2"><hr/></div>
    <p class="section-heading">Patents</p>
    <!-- Create a copy of pubs-box for a new entry and pubs-section for a group of entries-->

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/filed.jpeg" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Machine Learning Models for Mapping Between Image Sensor Color Patterns
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Maria Lyubimsteva, Zihan Xu, Desmond Kamas, Hemang Mehta, Vitalii Dziuba, Ed Chang
        </p>
        <p>
          <span class="venue">GP-307568-00-PCT - Filed</span>
          <!-- <span class="links">
            <a href="https://openreview.net/pdf?id=TwZ2sY6eJj" target="_blank">pdf</a>
          </span> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/filed.jpeg" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Learning-based Camera Auto-Focus Prediction for Sparse Phase Detection Imaging Sensors
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Stanley Chen*, Joa Lerman*, Zihan Xu*, Maria Lyubimtseva*, Ed Chang, Andrey Yatsunenko, Katrina Passarella, Jwalant Bhatt, David Tian, Desmond Kamas, Hemang Mehta, Gerardo Carranza, Vitalii Dziuba
        </p>
        <p>
          <span class="venue">PCT/US23/17752 - Filed</span>
          <!-- <span class="links">
            <a href="https://openreview.net/pdf?id=TwZ2sY6eJj" target="_blank">pdf</a>
          </span> -->
      </div>
    </div>
    

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Video Retrieval Based on Encoding Temporal Relationships Among Video Frames
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Harnish Lakhani, Atishay Jain
        </p>
        <p>
          <span class="venue">US 11,238,093 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/47/a3/7c/90801cadb58d7e/US11238093.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Deep Learning based Visual Compatibility Prediction for Bundle Recommendations
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Ayush Chopra, Utkarsh Patel, Balaji K, Anirudh Singhal
        </p>
        <p>
          <span class="venue">US 18/186,528 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/d7/10/38/8901c335c45044/US20230316379A1.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Video Retrieval Using Temporal Video Content
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Harnish Lakhani, Atishay Jain
        </p>
        <p>
          <span class="venue">US 16/601,773 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/0c/74/2e/8b43e3404a0b2d/US20210109966A1.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Machine Learning Predictions of Recommended Products in Augmented Reality Environments
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Harnish Lakhani, Atishay Jain
        </p>
        <p>
          <span class="venue">US 16/675,606 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/e4/17/c9/8b97158abedffd/US20210133850A1.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Augmented Viewpoint Driven Bundle Recommendation in Virtual Commerce
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Atishay Jain, Harnish Lakhani
        </p>
        <p>
          <span class="venue">US 17/654,885 - Filed</span>
          <!-- <span class="links">
            <a href="https://patentimages.storage.googleapis.com/e4/17/c9/8b97158abedffd/US20210133850A1.pdf" target="_blank">pdf</a>
          </span> -->
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Accurately Generating Virtual Try-On Images Utilizing a Unified Neural Network Framework
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Surgan Jandial, Ayush Chopra, Mayur Hemani, Balaji K
        </p>
        <p>
          <span class="venue">US 11,030,782 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/fd/ff/dc/8cc5a945e94727/US11030782.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Cloth warping using multi-scale patch adversarial loss
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Surgan Jandial, Ayush Chopra, Mayur Hemani, Balaji K
        </p>
        <p>
          <span class="venue">US 11,080,817 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/3c/0a/d5/e866dc3d8a36b0/US11080817.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Center-Biased Machine Learning Techniques to Determine Saliency in Digital Images
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Atishay Jain
        </p>
        <p>
          <span class="venue">US 11,663,463 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/1c/4a/cf/b14381063db9c0/US11663463.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Performance of Neural Networks Using Learned Specialized Transformation Functions
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>*, Abhishek Sinha*, Ayush Chopra*, Hiresh Gupta*, Mausoom Sarkar*, Balaji K
        </p>
        <p>
          <span class="venue">US 16/534,856 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/a3/61/60/6359736413d2fb/US20210042625A1.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Compatibility Based Identification of Incompatible Products in Digital Representations of Real-World Environments
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Harnish Lakhani, Atishay Jain
        </p>
        <p>
          <span class="venue">US 10,984,467 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/a0/ef/42/78f1fcc108b908/US10984467.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Automatic Generation of Context-Aware Composite Images
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Harsh Vardhan Chopra
        </p>
        <p>
          <span class="venue">US 11,158,100 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/30/18/4f/d05dcaaf170dbc/US11158100.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Generating and Providing Augmented Reality Representations of Recommended Products Based on Style Compatibility in Relation to Real-World Surroundings
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Gaurush Hiranandani
        </p>
        <p>
          <span class="venue">US 10,789,622 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/dc/19/f2/4c144ff675d266/US10789622.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Generating and Providing Augmented Reality Representations of Recommended Products Based on Style Similarity in Relation to Real-World Surroundings
        </p>
        <p class="authors">
          <em>Kumar Ayush</em>, Gaurush Hiranandani
        </p>
        <p>
          <span class="venue">US 10,956,967 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/fb/ae/af/788bd97d219916/US10956967.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Creating Personalized Catalogues with Recommendations Embedded in Augmented Viewpoint to Retarget Consumers
        </p>
        <p class="authors">
          Gaurush Hiranandani, <em>Kumar Ayush</em>, Sai Varun Maram Reddy, Chinnaobireddy Varsha,  Siddhant Jain
        </p>
        <p>
          <span class="venue">AU 2017216603 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/5e/af/5b/c457ea21074f71/AU2017216603A1.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Method, Medium, and System for Product Recommendations based on Augmented Reality Viewpoints
        </p>
        <p class="authors">
          Gaurush Hiranandani, Sai Varun Reddy Maram, <em>Kumar Ayush</em>, Chinnaobireddy Varsha, Siddhant Jain
        </p>
        <p>
          <span class="venue">US 10,475,103 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/9f/df/91/4337989ab052cb/US10475103.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>


    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Creating Targeted Content based on Detected Characteristics of an Augmented Reality Scene
        </p>
        <p class="authors">
          Gaurush Hiranandani, <em>Kumar Ayush</em>, Chinnaobireddy Varsha, Sai Varun Maram Reddy
        </p>
        <p>
          <span class="venue">US 10,922,716 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/17/ab/7e/555179c4146b23/US10922716.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Product Recommendations Based on Augmented Reality Viewpoints
        </p>
        <p class="authors">
          Gaurush Hiranandani, Sai Varun Maram Reddy, <em>Kumar Ayush</em>, Chinnaobireddy Varsha,  Siddhant Jain
        </p>
        <p>
          <span class="venue">US 2018/0121988 -</span>
          <span class="links">
            <a href="https://patents.google.com/patent/US20180121988A1/en" target="_blank">pdf</a>
          </span>
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-image">
        <img src="./images/patent.png" />
      </div>
      <div class="pubs-data">
        <p class="title">
          Identifying Augmented Reality Visuals Influencing User Behavior in Virtual-Commerce Environments
        </p>
        <p class="authors">
          Gaurush Hiranandani, Chinnaobireddy Varsha, Sai Varun Maram Reddy, <em>Kumar Ayush</em>, Atanu R Sinha
        </p>
        <p>
          <span class="venue">US 10,163,269 -</span>
          <span class="links">
            <a href="https://patentimages.storage.googleapis.com/f6/95/79/2478d2710f7982/US10163269.pdf" target="_blank">pdf</a>
          </span>
      </div>
    </div>

  </div>

  <div class="full-project-divider2">
    <hr />
  </div>

  <footer>
    <small>&copy; 2025, Kumar Ayush &emsp; &emsp; &emsp; Template used from this
      <a href="https://github.com/VSehwag/vsehwag.github.io" , target="_blank">website.</a>
    </small>
  </footer>
</body>
